{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.6.10 64-bit ('pytorch_latest_p36': conda)",
   "display_name": "Python 3.6.10 64-bit ('pytorch_latest_p36': conda)",
   "metadata": {
    "interpreter": {
     "hash": "4c1e195df8d07db5ee7a78f454b46c3f2e14214bf8c9489d2db5cf8f372ff2ed"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/bin/bash: aws: command not found\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp s3://amazon-reviews-pds/tsv/amazon_reviews_us_Camera_v1_00.tsv.gz ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "b'Skipping line 85458: expected 15 fields, saw 22\\nSkipping line 91161: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 166123: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 225458: expected 15 fields, saw 22\\nSkipping line 229936: expected 15 fields, saw 22\\nSkipping line 259297: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 284728: expected 15 fields, saw 22\\nSkipping line 286334: expected 15 fields, saw 22\\nSkipping line 293400: expected 15 fields, saw 22\\nSkipping line 294415: expected 15 fields, saw 22\\nSkipping line 308150: expected 15 fields, saw 22\\nSkipping line 315022: expected 15 fields, saw 22\\nSkipping line 315730: expected 15 fields, saw 22\\nSkipping line 316071: expected 15 fields, saw 22\\nSkipping line 326729: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 329101: expected 15 fields, saw 22\\nSkipping line 333077: expected 15 fields, saw 22\\nSkipping line 377031: expected 15 fields, saw 22\\nSkipping line 389496: expected 15 fields, saw 22\\nSkipping line 390486: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 418308: expected 15 fields, saw 22\\nSkipping line 454332: expected 15 fields, saw 22\\nSkipping line 458342: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 460704: expected 15 fields, saw 22\\nSkipping line 466250: expected 15 fields, saw 22\\nSkipping line 486023: expected 15 fields, saw 22\\nSkipping line 492819: expected 15 fields, saw 22\\nSkipping line 517468: expected 15 fields, saw 22\\nSkipping line 520963: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 528810: expected 15 fields, saw 22\\nSkipping line 554419: expected 15 fields, saw 22\\nSkipping line 565266: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 613248: expected 15 fields, saw 22\\nSkipping line 613988: expected 15 fields, saw 22\\nSkipping line 620134: expected 15 fields, saw 22\\nSkipping line 642170: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 670152: expected 15 fields, saw 22\\nSkipping line 681751: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 811638: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 913254: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1168305: expected 15 fields, saw 22\\n'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"amazon_reviews_us_Camera_v1_00.tsv.gz\",  sep='\\t', compression='gzip', error_bad_lines=False, dtype='str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# org_df = df\n",
    "# df = org_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                         review_body star_rating\n",
       "1          Perfect, even sturdier than the original!           5\n",
       "3  Exactly what I wanted and expected. Perfect fo...           5\n",
       "4  I will look past the fact that they tricked me...           5\n",
       "7                        Great camera for the price.           5\n",
       "8  Product is very good and satisfactory.<br /><b...           5"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review_body</th>\n      <th>star_rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>Perfect, even sturdier than the original!</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Exactly what I wanted and expected. Perfect fo...</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I will look past the fact that they tricked me...</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Great camera for the price.</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Product is very good and satisfactory.&lt;br /&gt;&lt;b...</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 248
    }
   ],
   "source": [
    "df.dropna(inplace=True)\n",
    "df = df[(df[\"review_body\"].astype(str).str.len() >10)]\n",
    "df = df[ (df[\"star_rating\"] == \"1\") | (df[\"star_rating\"] == \"5\")]\n",
    "df = df[[\"review_body\",\"star_rating\"]]\n",
    "df[\"star_rating\"] =  df[\"star_rating\"].astype(int)\n",
    "df[\"star_rating\"] =  df[\"star_rating\"].apply(lambda x: 1 if x == 5 else 0)\n",
    "# df = df[:100_000]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1    1020166\n",
       "0     168733\n",
       "Name: star_rating, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 256
    }
   ],
   "source": [
    "df[\"star_rating\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#BERT\n",
    "import transformers\n",
    "from transformers import BertModel, BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, reviews, targets, tokenizer):\n",
    "        self.reviews = reviews\n",
    "        self.targets = targets\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = 250\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.reviews)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "\n",
    "        review = self.reviews.iloc[item]\n",
    "        target = self.targets.iloc[item]\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            review,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            return_token_type_ids=False,\n",
    "            pad_to_max_length=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'review_text': review,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'targets': torch.tensor(target, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(\n",
    "    df,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=df[\"star_rating\"].values\n",
    ")\n",
    "\n",
    "train_ds = ReviewDataset(reviews = df_train[\"review_body\"], targets=df_train[\"star_rating\"], tokenizer=tokenizer)\n",
    "train_dl = DataLoader(train_ds, batch_size=16, num_workers=4)\n",
    "\n",
    "test_ds = ReviewDataset(reviews = df_test[\"review_body\"], targets=df_test[\"star_rating\"], tokenizer=tokenizer)\n",
    "test_dl = DataLoader(test_ds, batch_size=16, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "running epoch  0\n",
      "Process Process-162:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/multiprocessing/process.py\", line 261, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/multiprocessing/util.py\", line 322, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/multiprocessing/util.py\", line 262, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/multiprocessing/util.py\", line 186, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/multiprocessing/queues.py\", line 191, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/threading.py\", line 1056, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/threading.py\", line 1072, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f99b9fc02e8>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 962, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 942, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/multiprocessing/process.py\", line 124, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/multiprocessing/popen_fork.py\", line 50, in wait\n",
      "    return self.poll(os.WNOHANG if timeout == 0.0 else 0)\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/multiprocessing/popen_fork.py\", line 28, in poll\n",
      "    pid, sts = os.waitpid(self.pid, flag)\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-260-98b2e06b99db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m                         labels = labels)\n\u001b[1;32m     43\u001b[0m         \u001b[0mtotal_loss\u001b[0m\u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "EPOCHS = 2\n",
    "LEARNING_RATE = 1e-5\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "def ret_model():\n",
    "    model = BertForSequenceClassification.from_pretrained(\n",
    "        \"bert-base-uncased\", \n",
    "        num_labels = 2, \n",
    "        output_attentions = False, \n",
    "        output_hidden_states = False,\n",
    "    )\n",
    "    return model\n",
    "\n",
    "total_steps = len(train_dl) * EPOCHS\n",
    "\n",
    "model = ret_model()\n",
    "optim = AdamW(model.parameters(), lr=LEARNING_RATE, eps=1e-8)\n",
    "scheduler = get_linear_schedule_with_warmup(optim, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(\"running epoch \",epoch)\n",
    "    model = ret_model()\n",
    "    model.to(device)\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    for step, batch in enumerate(train_dl):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        input_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"targets\"].to(device)\n",
    "\n",
    "        model.zero_grad()\n",
    "        loss, logits = model(input_ids, \n",
    "                        token_type_ids=None,\n",
    "                        attention_mask = input_mask,\n",
    "                        labels = labels)\n",
    "        total_loss+= loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        optim.step()\n",
    "        scheduler.step()\n",
    "    avg_train_loss = total_loss / len(train_dl)\n",
    "    print(\"avg_train_loss\",avg_train_loss)\n",
    "    model.eval()\n",
    "    \n",
    "    total_eval_acc = 0\n",
    "    total_eval_loss = 0\n",
    "    eval_steps = 0\n",
    "\n",
    "    for batch in test_dl:\n",
    "        input_ids = batch[\"input_ids\"].cuda()\n",
    "        input_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"targets\"].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            loss, logits = model(input_ids, \n",
    "                        token_type_ids=None,\n",
    "                        attention_mask = input_mask,\n",
    "                        labels = labels)\n",
    "\n",
    "            total_eval_loss+= loss.item()\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            label_ids = labels.to(\"cpu\").numpy()\n",
    "            total_eval_acc += flat_accuracy(logits, label_ids)\n",
    "\n",
    "\n",
    "    avg_val_acc = total_eval_acc / len(test_dl)\n",
    "    print(\"Val acc\",avg_val_acc)\n",
    "    avg_val_loss = total_eval_loss / len(test_dl)\n",
    "    print(\"val loss\", avg_val_loss)\n"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = ret_model()\n",
    "model.load_state_dict(torch.load(\"model.pth\"))\n",
    "model.eval()\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "metadata": {},
     "execution_count": 203
    }
   ],
   "source": [
    "\n",
    "\n",
    "inputs = tokenizer.encode_plus(\n",
    "            'Perfect, even sturdier than the original',\n",
    "            add_special_tokens=True,\n",
    "            max_length=250,\n",
    "            return_token_type_ids=True,\n",
    "            pad_to_max_length=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "ids = inputs[\"input_ids\"]\n",
    "mask = inputs[\"attention_mask\"]\n",
    "token_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "outputs = model(ids, token_type_ids=token_type_ids, attention_mask=mask)\n",
    "# outputs\n",
    "preds = torch.sigmoid(outputs[0]).cpu().detach().numpy()\n",
    "# preds\n",
    "np.argmax(preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'DEVICE' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-137-1959d670442e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"I am happy\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpredict_sentiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-136-c8c468522814>\u001b[0m in \u001b[0;36mpredict_sentiment\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mtoken_type_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mtoken_type_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DEVICE' is not defined"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}