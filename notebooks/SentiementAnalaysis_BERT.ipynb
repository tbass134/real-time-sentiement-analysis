{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-10-15 18:48:56--  https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Camera_v1_00.tsv.gz\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.43.14\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.43.14|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 442653086 (422M) [application/x-gzip]\n",
      "Saving to: ‘amazon_reviews_us_Camera_v1_00.tsv.gz’\n",
      "\n",
      "amazon_reviews_us_C 100%[===================>] 422.15M  73.8MB/s    in 5.6s    \n",
      "\n",
      "2020-10-15 18:49:01 (75.6 MB/s) - ‘amazon_reviews_us_Camera_v1_00.tsv.gz’ saved [442653086/442653086]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Camera_v1_00.tsv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 85458: expected 15 fields, saw 22\\nSkipping line 91161: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 166123: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 225458: expected 15 fields, saw 22\\nSkipping line 229936: expected 15 fields, saw 22\\nSkipping line 259297: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 284728: expected 15 fields, saw 22\\nSkipping line 286334: expected 15 fields, saw 22\\nSkipping line 293400: expected 15 fields, saw 22\\nSkipping line 294415: expected 15 fields, saw 22\\nSkipping line 308150: expected 15 fields, saw 22\\nSkipping line 315022: expected 15 fields, saw 22\\nSkipping line 315730: expected 15 fields, saw 22\\nSkipping line 316071: expected 15 fields, saw 22\\nSkipping line 326729: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 329101: expected 15 fields, saw 22\\nSkipping line 333077: expected 15 fields, saw 22\\nSkipping line 377031: expected 15 fields, saw 22\\nSkipping line 389496: expected 15 fields, saw 22\\nSkipping line 390486: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 418308: expected 15 fields, saw 22\\nSkipping line 454332: expected 15 fields, saw 22\\nSkipping line 458342: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 460704: expected 15 fields, saw 22\\nSkipping line 466250: expected 15 fields, saw 22\\nSkipping line 486023: expected 15 fields, saw 22\\nSkipping line 492819: expected 15 fields, saw 22\\nSkipping line 517468: expected 15 fields, saw 22\\nSkipping line 520963: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 528810: expected 15 fields, saw 22\\nSkipping line 554419: expected 15 fields, saw 22\\nSkipping line 565266: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 613248: expected 15 fields, saw 22\\nSkipping line 613988: expected 15 fields, saw 22\\nSkipping line 620134: expected 15 fields, saw 22\\nSkipping line 642170: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 670152: expected 15 fields, saw 22\\nSkipping line 681751: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 811638: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 913254: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1168305: expected 15 fields, saw 22\\n'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"amazon_reviews_us_Camera_v1_00.tsv.gz\",  sep='\\t', compression='gzip', error_bad_lines=False, dtype='str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Perfect, even sturdier than the original!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Great camera for the price.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Use these all the time.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>very good on batteries, recommended</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>It is a very good starter set for this camera</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           review  rating\n",
       "1       Perfect, even sturdier than the original!       1\n",
       "7                     Great camera for the price.       1\n",
       "11                        Use these all the time.       1\n",
       "15            very good on batteries, recommended       1\n",
       "17  It is a very good starter set for this camera       1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(inplace=True)\n",
    "df = df[ (df[\"review_body\"].astype(str).str.len() >10) & (df[\"review_body\"].astype(str).str.len() <=64)]\n",
    "df = df[ (df[\"star_rating\"] == \"1\") | (df[\"star_rating\"] == \"5\")]\n",
    "df = df[[\"review_body\",\"star_rating\"]]\n",
    "df[\"star_rating\"] =  df[\"star_rating\"].astype(int)\n",
    "df[\"star_rating\"] =  df[\"star_rating\"].apply(lambda x: 1 if x == 5 else 0)\n",
    "df.columns = [\"review\",\"rating\"]\n",
    "# df = df[:100_000]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    15551\n",
       "0    15551\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "df_majority = df[df['rating']==1]\n",
    "df_minority = df[df['rating']==0]\n",
    "\n",
    "maj_class1 = resample(df_majority, replace=True,n_samples=len(df_minority))\n",
    "df = pd.concat([maj_class1, df_minority])\n",
    "df[\"rating\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "for sent in df[\"review\"]:\n",
    "    if len(sent) > max_len:\n",
    "        max_len = len(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = df[\"review\"].values\n",
    "labels = df[\"rating\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    15551\n",
       "0    15551\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"rating\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31102"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#BERT\n",
    "import transformers\n",
    "from transformers import BertModel, BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "for sent in sentences:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent,\n",
    "                        add_special_tokens = True,\n",
    "                        max_length = 64,\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,\n",
    "                        truncation=True,\n",
    "                        return_tensors = 'pt'\n",
    "                   )\n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27,991 training samples\n",
      "3,111 validation samples\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, random_split\n",
    "\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print('{:>5,} training samples'.format(train_size))\n",
    "print('{:>5,} validation samples'.format(val_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "batch_size = 32\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,\n",
    "            sampler = RandomSampler(train_dataset),\n",
    "            batch_size = batch_size\n",
    "        )\n",
    "\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset,\n",
    "            sampler = SequentialSampler(val_dataset),\n",
    "            batch_size = batch_size\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running epoch  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/conda-bld/pytorch_1587428091666/work/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_train_loss 0.12130771941159453\n",
      "  Accuracy: 0.98\n",
      "  Validation Loss: 0.08\n",
      "running epoch  1\n",
      "avg_train_loss 0.06251509219620908\n",
      "  Accuracy: 0.98\n",
      "  Validation Loss: 0.07\n",
      "running epoch  2\n",
      "avg_train_loss 0.046090476284069676\n",
      "  Accuracy: 0.98\n",
      "  Validation Loss: 0.08\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 3\n",
    "LEARNING_RATE = 1e-5\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "def ret_model():\n",
    "    model = BertForSequenceClassification.from_pretrained(\n",
    "        \"bert-base-uncased\", \n",
    "        num_labels = 2, \n",
    "        output_attentions = False, \n",
    "        output_hidden_states = False,\n",
    "    )\n",
    "    return model\n",
    "\n",
    "total_steps = len(train_dataloader) * EPOCHS\n",
    "\n",
    "model = ret_model()\n",
    "model.to(device)\n",
    "optim = AdamW(model.parameters(), lr=LEARNING_RATE, eps=1e-8)\n",
    "scheduler = get_linear_schedule_with_warmup(optim, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "\n",
    "\n",
    "for epoch in range(0, EPOCHS):\n",
    "    print(\"running epoch \",epoch)\n",
    "   \n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        model.zero_grad()\n",
    "        loss, logits = model(b_input_ids, \n",
    "                        token_type_ids=None,\n",
    "                        attention_mask = b_input_mask,\n",
    "                        labels = b_labels)\n",
    "        \n",
    "        total_loss+= loss.item()\n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "\n",
    "        optim.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "    print(\"avg_train_loss\",avg_train_loss)\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    total_eval_acc = 0\n",
    "    total_eval_loss = 0\n",
    "    eval_steps = 0\n",
    "\n",
    "    for batch in validation_dataloader:\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            loss, logits = model(b_input_ids, \n",
    "                        token_type_ids=None,\n",
    "                        attention_mask = b_input_mask,\n",
    "                        labels = b_labels)\n",
    "\n",
    "        total_eval_loss+= loss.item()\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to(\"cpu\").numpy()\n",
    "        \n",
    "        total_eval_acc += flat_accuracy(logits, label_ids)\n",
    "\n",
    "\n",
    "    avg_val_acc = total_eval_acc / len(validation_dataloader)\n",
    "    print(\"  Accuracy: {0:.2f}\".format(avg_val_acc))\n",
    "    \n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = ret_model()\n",
    "model.load_state_dict(torch.load(\"model.pth\"))\n",
    "model.eval()\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_sentiment(sentence):\n",
    "    inputs = tokenizer.encode_plus(\n",
    "                sentence,\n",
    "                add_special_tokens=True,\n",
    "                max_length=64,\n",
    "                return_token_type_ids=True,\n",
    "                pad_to_max_length=True,\n",
    "                return_attention_mask=True,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "    ids = inputs[\"input_ids\"]\n",
    "    mask = inputs[\"attention_mask\"]\n",
    "    token_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "    outputs = model(ids, token_type_ids=token_type_ids, attention_mask=mask)\n",
    "    preds = torch.sigmoid(outputs[0]).cpu().detach().numpy()\n",
    "    return np.argmax(preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_sentiment(\"this is great\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_sentiment(\"worst product ever\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_latest_p36)",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
